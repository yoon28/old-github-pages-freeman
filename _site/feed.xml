<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Kwangjin Yoon</title>
    <description>This is a github page.</description>
    <link>/</link>
    <atom:link href="/zfeed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Fri, 02 Sep 2016 16:29:51 +0900</pubDate>
    <lastBuildDate>Fri, 02 Sep 2016 16:29:51 +0900</lastBuildDate>
    <generator>Jekyll v3.2.1</generator>
    
      <item>
        <title>Udacity lecture 03</title>
        <description>&lt;h2 id=&quot;udacity-deep-learning-3&quot;&gt;Udacity Deep learning 3강&lt;/h2&gt;
&lt;p&gt;&lt;br /&gt;
영상 처리에서 Convolution은 널리 알려진 연산자이다. Convolutional Neural Network(CNN)는 네트워크의 히든 레이어를 구성할때 Convolution 연산을 사용한다. 이때 특이한 점은, input의 depth와 output의 depth가 다를 수 있다. 아래 그림을 보면 input은 3채널의 영상으로 depth가 3이지만 output은 depth가 K인 것을 확인할 수 있다.
\[ \frac{1}{n^{2}} \]
&lt;img src=&quot;https://i.imgur.com/Gov5CHo.png&quot; alt=&quot;img1&quot; title=&quot;con&quot; /&gt;&lt;/p&gt;

&lt;!-- more --&gt;

&lt;p&gt;&lt;br /&gt;
아래 그림은 Feature Map의 Dimension을 구체적으로 나타내면서 CNN의 구조를 파악한 것이다. 우선 처음 두개의 레이어를 보면, 첫번째 입력으로 256x256 크기의 3채널 영상이 주어졌고 그로부터 depth가 16인 128x128짜리 Feature map이 생성된 것을 볼 수가 있다. 이것으로부터 유추해보면, stride가 2인 convolution 연산이 있었음을 생각해 볼수 있다. 또 depth를 3에서 16으로 증강시키는 convolution 연산이 있었음을 생각해 볼수 있다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.imgur.com/c65a4Yf.png&quot; alt=&quot;img2&quot; title=&quot;conv&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;
Udacity 3강의 숙제에서 CNN의 Network 구조에 관련된 코드이다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;# Model.&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;conv&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;conv2d&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;layer1_weights&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;padding&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'SAME'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;hidden&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;relu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;conv&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;layer1_biases&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;conv&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;conv2d&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hidden&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;layer2_weights&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;padding&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'SAME'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;hidden&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;relu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;conv&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;layer2_biases&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hidden&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get_shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;as_list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;reshape&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reshape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hidden&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]])&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;hidden&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;relu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;matmul&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reshape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;layer3_weights&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;layer3_biases&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;matmul&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hidden&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;layer4_weights&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;layer4_biases&lt;/span&gt;

&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;우선 위 코드에서 model 함수가 받는 인자 data는 1채널의 28x28 사이즈 영상이다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  &lt;span class=&quot;n&quot;&gt;conv&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;conv2d&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;layer1_weights&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;padding&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'SAME'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;hidden&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;relu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;conv&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;layer1_biases&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;위에서 layer1_weights 변수는 CNN의 첫번째 convolution kernel이고 1x5x5x16의 크기를 가지며, tf.nn.conv2d 함수에 의해 2칸씩 stride를 하며 convolution을 한다. kernel dimension의 처음 세개(1x5x5)는 input patch의 size를 말하고, 마지막 16은 convolution의 output depth의 size를 말한다.이다. layer1_biases의 dimension은 1x16이며 convolution 연산의 결과에 더하여 ReLu의 입력이 된다. 즉, 첫번째 hidden layer의 dimension은 14x14x16이 된다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  &lt;span class=&quot;n&quot;&gt;conv&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;conv2d&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hidden&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;layer2_weights&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;padding&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'SAME'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;hidden&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;relu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;conv&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;layer2_biases&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;두 번째 hidden layer를 구성하기 위한 부분이고, layer2_weights의 dimension은 16x5x5x16이고 이것 역시 2칸씩 stride를 하며 convolution을 한다. 이렇게 해서 생성되는 hidden layer는 다시 한번 크기가 줄어 7x7x16이 된다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  &lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hidden&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get_shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;as_list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;reshape&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reshape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hidden&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]])&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;hidden&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;relu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;matmul&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reshape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;layer3_weights&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;layer3_biases&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;matmul&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hidden&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;layer4_weights&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;layer4_biases&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;이 부분부터는 convolution이 적용되지 않았다.
7x7x16의 feature map을 1x784의 벡터로 변형한다. tf.reshape( … ) 함수가 그 부분이다.
그리고 784x64 크기의 매트릭스와 곱셈하고 1x64 크기의 벡터 bias와 더하여 다음 1x64짜리 layer를 만든다. 위의 세 번째 줄이 그것이다. 마지막으로 64x10짜리 매트릭스인 layer4_weights와 1x10짜리 벡터 layer4_biases를 사용해 최종 output인 logits을 얻는다.&lt;/p&gt;

</description>
        <pubDate>Mon, 28 Mar 2016 00:00:00 +0900</pubDate>
        <link>/deep%20learning/2016/03/28/udacity-lec03.html</link>
        <guid isPermaLink="true">/deep%20learning/2016/03/28/udacity-lec03.html</guid>
        
        <category>Deep learning</category>
        
        <category>Tensorflow</category>
        
        <category>Udacity lecture</category>
        
        
        <category>Deep learning</category>
        
      </item>
    
      <item>
        <title>Minimum cost flow</title>
        <description>&lt;h2 id=&quot;minimum-cost-flow-problem&quot;&gt;Minimum cost flow problem&lt;/h2&gt;
&lt;p&gt;Minimum cost flow(MCF) 문제는 주어진 그래프와 제약 조건을 만족하는 최소 비용의 flow를 구하는 문제이다.
&lt;!-- more --&gt;
&lt;br /&gt;&lt;/p&gt;

&lt;h3 id=&quot;mcf-&quot;&gt;MCF의 그래프&lt;/h3&gt;
&lt;p&gt;MCF에서 그래프는 노드(Node)와 방향성이 있는 간선(Edge)으로 이루어져있다. 즉, 그래프 &lt;script type=&quot;math/tex&quot;&gt;G=(V,E)&lt;/script&gt;의 모든 간선 &lt;script type=&quot;math/tex&quot;&gt;(i,j)\in E&lt;/script&gt;는 노드 &lt;script type=&quot;math/tex&quot;&gt;i&lt;/script&gt;에서 노드&lt;script type=&quot;math/tex&quot;&gt;j&lt;/script&gt;로 흐르는 방향의 간선이다. 이때 &lt;script type=&quot;math/tex&quot;&gt;i,j \in V&lt;/script&gt;이다. 또 모든 간선들은 &lt;strong&gt;capacity&lt;/strong&gt; &lt;script type=&quot;math/tex&quot;&gt;u_{ij}&lt;/script&gt;와 &lt;strong&gt;cost&lt;/strong&gt; &lt;script type=&quot;math/tex&quot;&gt;c_{ij}&lt;/script&gt;를 갖는다. &lt;script type=&quot;math/tex&quot;&gt;u_{ij}&lt;/script&gt;는 간선 &lt;script type=&quot;math/tex&quot;&gt;(i,j)&lt;/script&gt;에 흐를수 있는 &lt;strong&gt;최대 flow&lt;/strong&gt;를 나타내며, &lt;script type=&quot;math/tex&quot;&gt;c_{ij}&lt;/script&gt;는 간선 &lt;script type=&quot;math/tex&quot;&gt;(i,j)&lt;/script&gt;를 흐르는 &lt;strong&gt;하나의 flow당 소요되는 cost&lt;/strong&gt;를 말한다. 그리고 모든 노드 &lt;script type=&quot;math/tex&quot;&gt;i \in V&lt;/script&gt;는 &lt;strong&gt;supply&lt;/strong&gt; &lt;script type=&quot;math/tex&quot;&gt;b_{i}&lt;/script&gt;를 갖는다. &lt;script type=&quot;math/tex&quot;&gt;b_{i}&lt;/script&gt;가 &lt;script type=&quot;math/tex&quot;&gt;0&lt;/script&gt;보다 클 경우 노드 &lt;script type=&quot;math/tex&quot;&gt;i&lt;/script&gt;를 &lt;strong&gt;supply node&lt;/strong&gt;라 부르고, &lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
b_{i}&lt;0 %]]&gt;&lt;/script&gt;이면 &lt;strong&gt;demand node&lt;/strong&gt;라 부른다. 만약 &lt;script type=&quot;math/tex&quot;&gt;b_{i}=0&lt;/script&gt;이면 &lt;strong&gt;transshipment node&lt;/strong&gt;라 부른다. 아래 사진은 MCF 그래프의 한 예이다. 6개의 노드와 7개의 간선으로 이루어진 것을 확인 할 수 있다. 예제로부터 간선 &lt;script type=&quot;math/tex&quot;&gt;(1,3)&lt;/script&gt;은 3의 &lt;strong&gt;capacity&lt;/strong&gt;와 4의 &lt;strong&gt;cost&lt;/strong&gt;를 가지며 노드 1은 &lt;script type=&quot;math/tex&quot;&gt;b_{1}&lt;/script&gt; 값이 5이므로 &lt;strong&gt;supply node&lt;/strong&gt;이다.&lt;/p&gt;

&lt;p class=&quot;center&quot;&gt;&lt;img src=&quot;http://community.topcoder.com/i/education/minimumCostFlow/Figure_1_1.png&quot; alt=&quot;graph example&quot; title=&quot;graph example&quot; /&gt;&lt;/p&gt;

&lt;p class=&quot;center&quot;&gt;&lt;sub&gt;&lt;em&gt;위 그림은 &lt;a href=&quot;https://www.topcoder.com/community/data-science/data-science-tutorials/minimum-cost-flow-part-one-key-concepts/&quot;&gt;topcoder&lt;/a&gt; 에서 발췌한 것 입니다.&lt;/em&gt;&lt;/sub&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h3 id=&quot;mcf--&quot;&gt;MCF의 제약 조건&lt;/h3&gt;
&lt;p&gt;간선 &lt;script type=&quot;math/tex&quot;&gt;(i,j)\in E&lt;/script&gt;를 흐르는 flow를 &lt;script type=&quot;math/tex&quot;&gt;x_{ij}&lt;/script&gt;라고 하자. 그러면 MCF 문제는 다음의 값을 최소화하는 최적화 문제이다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\min_{x_{ij}} \sum_{(i,j)\in E} c_{ij}x_{ij}&lt;/script&gt;

&lt;p&gt;더불어 다음의 두가지 제약 조건을 만족하여야 한다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\sum_{(i,j)\in E}x_{ij} - \sum_{(j,i)\in E}x_{ji} = b_{i} \text{, for all } i \in V&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;0 \leq x_{ij} \leq u_{ij} \text{, for all } (i,j)\in E&lt;/script&gt;

&lt;p&gt;첫 번째 제약 조건을 &lt;strong&gt;flow conservation constraint&lt;/strong&gt;라고 부른다. 이 제약 조건은 어떤 노드 &lt;script type=&quot;math/tex&quot;&gt;i&lt;/script&gt;에서 &lt;strong&gt;나가는 flow의 총합&lt;/strong&gt;과 &lt;strong&gt;들어오는 flow의 총합&lt;/strong&gt;의 차이가 &lt;script type=&quot;math/tex&quot;&gt;b_{i}&lt;/script&gt;와 같아야 함을 말한다. 두 번째 제약 조건은 간선 &lt;script type=&quot;math/tex&quot;&gt;(i,j)&lt;/script&gt;를 흐르는 flow &lt;script type=&quot;math/tex&quot;&gt;x_{ij}&lt;/script&gt;의 크기에 대한 제약 조건인데 이 크기가 0보다 크거나 같고 &lt;strong&gt;capacity&lt;/strong&gt; &lt;script type=&quot;math/tex&quot;&gt;u_{ij}&lt;/script&gt;보다 작거나 같아야함을 말한다.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;작성 중..&lt;/em&gt;&lt;/p&gt;
</description>
        <pubDate>Sun, 12 Jul 2015 00:00:00 +0900</pubDate>
        <link>/algorithms/2015/07/12/networkflow.html</link>
        <guid isPermaLink="true">/algorithms/2015/07/12/networkflow.html</guid>
        
        <category>Min cost flow</category>
        
        
        <category>Algorithms</category>
        
      </item>
    
  </channel>
</rss>
