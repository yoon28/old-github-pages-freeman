---
published: true
title: Udacity lecture 03
layout: post
author: Kwangjin Yoon 
category: Deep learning
tags: 
- Deep learning 
- Tensorflow
- Udacity lecture
---

## Udacity Deep learning 3강
<br>
영상 처리에서 Convolution은 널리 알려진 연산자이다. Convolutional Neural Network(CNN)는 네트워크의 히든 레이어를 구성할때 Convolution 연산을 사용한다. 이때 특이한 점은, input의 depth와 output의 depth가 다를 수 있다. 아래 그림을 보면 input은 3채널의 영상으로 depth가 3이지만 output은 depth가 K인 것을 확인할 수 있다.

![img1](https://i.imgur.com/Gov5CHo.png "con")

<!-- more -->

<br>
아래 그림은 Feature Map의 Dimension을 구체적으로 나타내면서 CNN의 구조를 파악한 것이다. 우선 처음 두개의 레이어를 보면, 첫번째 입력으로 256x256 크기의 3채널 영상이 주어졌고 그로부터 depth가 16인 128x128짜리 Feature map이 생성된 것을 볼 수가 있다. 이것으로부터 유추해보면, stride가 2인 convolution 연산이 있었음을 생각해 볼수 있다. 또 depth를 3에서 16으로 증강시키는 convolution 연산이 있었음을 생각해 볼수 있다.

![img2](https://i.imgur.com/c65a4Yf.png "conv")

<br>
Udacity 3강의 숙제에서 CNN의 Network 구조에 관련된 코드이다.

```python
# Model.
def model(data):
  conv = tf.nn.conv2d(data, layer1_weights, [1, 2, 2, 1], padding='SAME')
  hidden = tf.nn.relu(conv + layer1_biases)
  conv = tf.nn.conv2d(hidden, layer2_weights, [1, 2, 2, 1], padding='SAME')
  hidden = tf.nn.relu(conv + layer2_biases)
  shape = hidden.get_shape().as_list()
  reshape = tf.reshape(hidden, [shape[0], shape[1] * shape[2] * shape[3]])
  hidden = tf.nn.relu(tf.matmul(reshape, layer3_weights) + layer3_biases)
  return tf.matmul(hidden, layer4_weights) + layer4_biases

```

우선 위 코드에서 model 함수가 받는 인자 data는 1채널의 28x28 사이즈 영상이다. 

```python
  conv = tf.nn.conv2d(data, layer1_weights, [1, 2, 2, 1], padding='SAME')
  hidden = tf.nn.relu(conv + layer1_biases)
```
위에서 layer1_weights 변수는 CNN의 첫번째 convolution kernel이고 1x5x5x16의 크기를 가지며, tf.nn.conv2d 함수에 의해 2칸씩 stride를 하며 convolution을 한다. kernel dimension의 처음 세개(1x5x5)는 input patch의 size를 말하고, 마지막 16은 convolution의 output depth의 size를 말한다.이다. layer1_biases의 dimension은 1x16이며 convolution 연산의 결과에 더하여 ReLu의 입력이 된다. 즉, 첫번째 hidden layer의 dimension은 14x14x16이 된다.

```python
  conv = tf.nn.conv2d(hidden, layer2_weights, [1, 2, 2, 1], padding='SAME')
  hidden = tf.nn.relu(conv + layer2_biases)
```

두 번째 hidden layer를 구성하기 위한 부분이고, layer2_weights의 dimension은 16x5x5x16이고 이것 역시 2칸씩 stride를 하며 convolution을 한다. 이렇게 해서 생성되는 hidden layer는 다시 한번 크기가 줄어 7x7x16이 된다.

```python
  shape = hidden.get_shape().as_list()
  reshape = tf.reshape(hidden, [shape[0], shape[1] * shape[2] * shape[3]])
  hidden = tf.nn.relu(tf.matmul(reshape, layer3_weights) + layer3_biases)
  return tf.matmul(hidden, layer4_weights) + layer4_biases
```

이 부분부터는 convolution이 적용되지 않았다.
7x7x16의 feature map을 1x784의 벡터로 변형한다. tf.reshape( ... ) 함수가 그 부분이다.
그리고 784x64 크기의 매트릭스와 곱셈하고 1x64 크기의 벡터 bias와 더하여 다음 1x64짜리 layer를 만든다. 위의 세 번째 줄이 그것이다. 마지막으로 64x10짜리 매트릭스인 layer4_weights와 1x10짜리 벡터 layer4_biases를 사용해 최종 output인 logits을 얻는다.



